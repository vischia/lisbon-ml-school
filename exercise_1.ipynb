{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdd15d0-b18a-4b35-8cf8-c4e001c97b5f",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vischia/lisbon-ml-school/blob/master/exercise_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8afc560-312c-40e5-8188-62dc4c952efa",
   "metadata": {},
   "source": [
    "# Lisbon Machine Learning School\n",
    "## Exercise 1: data preprocessing, and neural network structure\n",
    "\n",
    "(C) Pietro Vischia (Universidad de Oviedo and ICTEA), pietro.vischia@cern.ch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe62fe-03ac-4127-a09a-a1340ae0f62a",
   "metadata": {},
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89093cba-9ae1-487b-a962-49ff7fe537da",
   "metadata": {},
   "source": [
    "- If you are running locally, you don't need to run anything\n",
    "\n",
    "- If you are running on Google Colab, uncomment and run the next cell (remove only the \"#\", keep the \"!\"). You can also run it from a local installation, but it will do nothing if you have already installed all dependencies (and it will take some time to tell you it is not gonna do anything).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c349fc5-c41c-4910-a16a-adc6068d7a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%cd \"/content/drive/MyDrive/\"\n",
    "#! git clone https://github.com/vischia/lisbon-ml-school.git\n",
    "#%cd lisbon-ml-school\n",
    "#!pwd\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40176774-7f04-4172-a635-0db7bf55e304",
   "metadata": {},
   "source": [
    "## Load the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f137b35-7bf7-446f-8c49-8487222a64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import torch.nn.functional as F \n",
    "import torchvision\n",
    "import torchinfo\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "\n",
    "import uproot\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8, 6)\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "\n",
    "print('Using torch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d75588-f79b-488f-9198-93ec2f70b967",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb19ea71-cb59-48c1-a235-491307ba7156",
   "metadata": {},
   "source": [
    "We will use simulated events corresponding to three physics processes.\n",
    "- ttH production\n",
    "- ttW production\n",
    "- Drell-Yan ($pp\\\\to Z/\\\\gamma^*$+jets) production\n",
    "\n",
    "We will select the multilepton final state, which is a challenging final state with a rich structure and nontrivial background separation.\n",
    "\n",
    "<img src=\"figs/2lss.png\" alt=\"ttH multilepton 2lss\" style=\"width:40%\"/>\n",
    "\n",
    "We use the [uproot](https://uproot.readthedocs.io/en/latest/basic.html) library to conveniently read in a [ROOT TNuple](https://root.cern.ch/doc/master/classTNtuple.html) which can automatically convert it to a [pandas dataframe](https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b0b7d4-1ff1-49bc-b9f9-4f870f239082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "--2025-03-12 12:44:47--  https://www.hep.uniovi.es/vischia/lisbon_ml_school/lisbon_ml_school_tth.tar.gz\n",
      "Resolviendo www.hep.uniovi.es (www.hep.uniovi.es)... 156.35.212.25\n",
      "conectado. con www.hep.uniovi.es (www.hep.uniovi.es)[156.35.212.25]:443... \n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 132407364 (126M) [application/x-gzip]\n",
      "Grabando a: «lisbon_ml_school_tth.tar.gz.1»\n",
      "\n",
      "lisbon_ml_school_tt 100%[===================>] 126,27M   974KB/s    en 2m 2s   \n",
      "\n",
      "2025-03-12 12:46:51 (1,03 MB/s) - «lisbon_ml_school_tth.tar.gz.1» guardado [132407364/132407364]\n",
      "\n",
      "x signal_blind20.root\n",
      "x background_1.root\n",
      "x background_2.root\n",
      "/Users/vischia/workarea_temp/lisbon_ml_school/lisbon-ml-school\n"
     ]
    }
   ],
   "source": [
    "# Download the data only if you haven't done so yet\n",
    "\n",
    "if not os.path.isfile(\"data/signal_blind20.root\"): \n",
    "    !mkdir data; cd data/; wget https://www.hep.uniovi.es/vischia/lisbon_ml_school/lisbon_ml_school_tth.tar.gz; tar xzvf lisbon_ml_school_tth.tar.gz; rm lisbon_ml_school_tth.tar.gz; cd -;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1088cba-7696-447e-b486-4ce372d374f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FOLDER = './data'\n",
    "\n",
    "sig = uproot.open(os.path.join(INPUT_FOLDER,'signal_blind20.root'))['Friends'].arrays(library=\"pd\")\n",
    "bk1 = uproot.open(os.path.join(INPUT_FOLDER,'background_1.root'))['Friends'].arrays(library=\"pd\")\n",
    "bk2 = uproot.open(os.path.join(INPUT_FOLDER,'background_2.root'))['Friends'].arrays(library=\"pd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d631f2-679f-41e5-a4dc-b8ba2c657add",
   "metadata": {},
   "source": [
    "### Data inspection\n",
    "\n",
    "The first thing you need to do when building a machine learning model is to forget about the model, and **just look at the data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a320d-365f-4f08-ac6a-01ca836ae57a",
   "metadata": {},
   "source": [
    "Let's start by looking at which features and labels are available in these files\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0a89a-f7ef-4fa0-9014-d3ee0d0460b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849782e-6db2-43cd-a597-03377b23e08d",
   "metadata": {},
   "source": [
    "Most of the variables are input features, corresponding to detector measurements of the properties of the reconstructed decay products.\n",
    "\n",
    "There are three special variables, though:\n",
    "\n",
    "- `Hreco_evt_tag`: this feature has values in ${0,1}$, where $1$ flags the event as signal event, and $0$ flags the event as background event;\n",
    "- `Hreco_HTXS_Higgs_pt`: this feature contains the true generate Higgs boson transverse momentum at generator level (used for regression);\n",
    "- `Hreco_HTXS_Higgs_y`: this feature contains the true generated Higgs boson rapidity (not pseudorapidity) at generator level (used for regression).\n",
    "\n",
    "You'll see down below that we will have of course to ignore some of all of these three features (they are not input features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50357d82-bbf6-4e56-b297-3b222075f306",
   "metadata": {},
   "source": [
    "### Plotting histograms of some observables using matplotlib\n",
    "(see also examples on [matplotlib](https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html) website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f700335-6cd4-4896-8c52-c79d4d88881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(sig[\"Hreco_Lep0_pt\"], bins=100)\n",
    "plt.xlabel(\"Lepton 1 $p_T$\")\n",
    "plt.ylabel(\"Events\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8349516-0fe8-45a9-a2a5-34a50aedbc98",
   "metadata": {},
   "source": [
    "We can also do scatter plots of one variable against the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592ae7b-bcb9-410e-913e-fde3037b019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(sig[\"Hreco_Lep0_pt\"], sig[\"Hreco_Lep1_pt\"])\n",
    "plt.xlabel(\"Lepton 1 $p_T$\")\n",
    "plt.ylabel(\"Lepton 2 $p_T$\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb0b6e7-9f6f-44b1-834b-e844ce377fb6",
   "metadata": {},
   "source": [
    "And another variable, the transverse momentum of the third lepton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af4a17-ce6f-4a5c-ba84-da8e8a60c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(sig[\"Hreco_Lep2_pt\"], bins=100)\n",
    "plt.xlabel(\"Lepton 3 $p_T$\")\n",
    "plt.ylabel(\"Events\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66adcce2-1307-4084-bb70-6039dc3755ff",
   "metadata": {},
   "source": [
    "What is going on in the last plot?\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea52fb-70d4-4463-979d-75a673b2f000",
   "metadata": {},
   "source": [
    "The events preselected in these files contain events that have **at least two** leptons with same electrical charge.\n",
    "\n",
    "Events with three leptons fall into this category.\n",
    "\n",
    "We have three choices:\n",
    "\n",
    "1. train our algorithm on `2lss` events, by selecting only events where the third lepton transverse momentum **is not set**: `dataframe=dataframe[dataframe['Hreco_Lep2_pt']==-99]`\n",
    "2. train our algorithm on `3l` events, by selecting only events where the third lepton transverse momentum **is set**: `dataframe=dataframe[dataframe['Hreco_Lep2_pt']>-99]`\n",
    "3. train our algorithm on `2lss+3l` events. The default value of $-99$ in this case will act as a semi-categorical variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe252a-508b-41ba-ac8d-c60638786a0f",
   "metadata": {},
   "source": [
    "Let's pick option (1). \n",
    "\n",
    "We will first create a label for signal or background events (we could also use the evt_tag variable), then join all datasets together, then filter events to keep only those corresponding to `2lss` events, and finally we will drop all the features corresponding to the third lepton, plus those corresponding to regression targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abb192-3784-48c5-b829-7a288f4e89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'label' and set its value to 1 or 0 for all rows (=events)\n",
    "sig['label'] = 1 \n",
    "bk1['label'] = 0\n",
    "bk2['label'] = 0\n",
    "\n",
    "# Merge the two backgrounds into one dataframe\n",
    "bkg = pd.concat([bk1, bk2])\n",
    "\n",
    "print(f\"bkg1 shape {bk1.shape}\")\n",
    "print(f\"bkg2 shape {bk2.shape}\")\n",
    "print(f\"bkg1+bkg2 shape {bkg.shape}\")\n",
    "\n",
    "# Merge the signal and background into one dataframe\n",
    "print(f\" Signal shape {sig.shape}\")\n",
    "print(f\" Bkg shape {bkg.shape}\")\n",
    "\n",
    "data = pd.concat([sig,bkg])\n",
    "\n",
    "print(f\" Data shape {data.shape}\")\n",
    "print(data.columns)\n",
    "\n",
    "# Filter data\n",
    "data=data[data['Hreco_Lep2_pt']==-99]\n",
    "# Drop unneeded features\n",
    "data = data.drop([\"Hreco_Lep2_pt\", \"Hreco_Lep2_eta\", \"Hreco_Lep2_phi\", \"Hreco_Lep2_mass\", \n",
    "                  \"Hreco_evt_tag\",\"Hreco_HTXS_Higgs_pt\", \"Hreco_HTXS_Higgs_y\"], axis=1 )\n",
    "\n",
    "\n",
    "print(f\" Data shape {data.shape}\")\n",
    "print(data.columns)\n",
    "print(f\"In this dataframe we finally have {data[data['label']==1].shape[0]} signal and {data[data['label']==0].shape[0]} background events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68295cd-910b-4863-9af2-074fb604abce",
   "metadata": {},
   "source": [
    "This data set is still ordered, ie. all signal events are before the background events. ML training requires a shuffled data set instead!\n",
    "\n",
    "We could also do that (and in fact we will) when randomly separating our dataset in training and test events, but it doesn't hurt to do it from the very beginning, to avoid forgetting it.\n",
    "\n",
    "We will also separate features and labels from each other, and check for corrupted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea526c-e4f1-47a1-89e7-1734df683361",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data.head(10)\n",
    "\n",
    "\n",
    "print(\"There are NaN-filled elements:\", data.isna().any().any())\n",
    "\n",
    "X = data.drop([\"label\"], axis=1)\n",
    "y = data[\"label\"]\n",
    "\n",
    "print(f\"data shape {data.shape}\")\n",
    "print(f\"input feature shape {X.shape}\")\n",
    "print(f\"label (=target) shape {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8019cbd6-9383-4bd5-a862-ca22f3b81944",
   "metadata": {},
   "source": [
    "We can inspect all the pairwise correlations between features, for signal and background separaterly,import seaborn as sns\n",
    "sns.set()\n",
    "cols_to_plot = [\n",
    "    'Hreco_Lep1_pt',\n",
    "    'Hreco_HadTop_pt',\n",
    "    'Hreco_All5_Jets_pt',\n",
    "    'Hreco_More5_Jets_pt',\n",
    "    'Hreco_Jets_plus_Lep_pt',\n",
    "    'label'\n",
    "]\n",
    "pp=sns.pairplot(data=data.sample(1000)[cols_to_plot], hue='label', diag_kws={'bw_method': 0.2})\n",
    "pp.map_lower(sns.kdeplot, levels=4, color=\".2\") # Contours as well as one-dimensional densities of individual features, by doing a `pairplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea510d8-8a08-4b9a-afd5-c1fcce317e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "cols_to_plot = [\n",
    "    'Hreco_Lep1_pt',\n",
    "    'Hreco_HadTop_pt',\n",
    "    'Hreco_All5_Jets_pt',\n",
    "    'Hreco_More5_Jets_pt',\n",
    "    'Hreco_Jets_plus_Lep_pt',\n",
    "    'label'\n",
    "]\n",
    "pp=sns.pairplot(data=data.sample(1000)[cols_to_plot], hue='label', diag_kws={'bw_method': 0.2})\n",
    "pp.map_lower(sns.kdeplot, levels=4, color=\".2\") # Contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2abdfcc-e115-4596-b5d2-abc7825c4af6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Exercise: what happens if you plot the full list of variables (`cols_to_plot = data.columns`) from the command above? What happens if you omit `.sample(100)` from the command above?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa22604-2037-4038-a5cc-275403e331cc",
   "metadata": {},
   "source": [
    "### Split the data set into training and test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41324f-fe1c-4ad1-adee-e4fb7cbd3745",
   "metadata": {},
   "source": [
    "When we train a machine learning algorithm, we are trying to solve an interpolation problem (find the function of the input features that provides the best approximation of the true function) by also requiring that the solution generalizes sufficiently well (the interpolating function must also predict correctly the value of the true function for new, unseen data).\n",
    "\n",
    "When we have a labelled dataset, we will therefore split it into: a training set, which we will use to train the machine learning algorithm; a test set, which we will use to evaluate the performance of the algorithm for various realizations of the algorithm (e.g. tuning hyperparameters); and an application set, which are the data we are really interested in studying in the end.\n",
    "\n",
    "For many applications, when the amount of hyperparameters tuning is moderate, application set and test set can be collapsed into a single set (usually called test set). This is what we will do in this tutorial.\n",
    "\n",
    "![Blah](figs/trainingNetwork.png)\n",
    "\n",
    "(Image: P. Vischia, [doi:10.5281/zenodo.6373442](https://doi.org/10.5281/zenodo.6373442))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff38ff-768f-47b0-9091-8a5440c73522",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"We have {len(X_train)} training samples with {sum(y_train)} signal and {sum(1-y_train)} background events\")\n",
    "print(f\"We have {len(X_test)} testing samples with {sum(y_test)} signal and {sum(1-y_test)} background events\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8bd17-4dc3-4f0b-bb83-7a7faf8fdb17",
   "metadata": {},
   "source": [
    "### Correlation matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae58c9c-7252-45a7-aca3-7cbcb9cf6ca8",
   "metadata": {},
   "source": [
    "For classification problems, another important thing is to take a look at the correlations between all the variables, in events belonging to each class separately.\n",
    "\n",
    "Looking at the correlation between features can highlight pairs that are strongly correlated with each other, and one could decide to omit them since they do not add further information when the correlations are very high.\n",
    "\n",
    "We look at the correlation for each class because we are very interested in pairs of features that have different correlation in one class or the other (in our example, signal or background).\n",
    "\n",
    "Now we will choose a simple criterion, for instance the value of one of the features that characterize the houses, and use it to decide if the house is in New York (we want to predict 0) or in San Francisco (we want to predict 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee05c6f-e7fa-47a0-b739-36705aef99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrmatrix(corr, label):\n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(\n",
    "        corr, \n",
    "        vmin=-1., vmax=1., center=0.,\n",
    "        cmap=sns.diverging_palette(20., 220., n=200, as_cmap=True),\n",
    "        square=True\n",
    "    )\n",
    "    ax.set_xticklabels(\n",
    "        ax.get_xticklabels(),\n",
    "        rotation=45,\n",
    "        horizontalalignment='right'\n",
    "    );\n",
    "\n",
    "    ax.set_title('Correlation matrix for %s events' % label)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "corrmatrix(X_train[y_train==1.].corr(), 'signal')\n",
    "corrmatrix(X_train[y_train==0.].corr(), 'background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a4c0c-7294-4f0a-a260-6dc57e519a23",
   "metadata": {},
   "source": [
    "What we have plotted is the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), which leads to an important limitation of this diagnostic tool. The Pearson correlation coefficient captures only **linear** correlation between variables, and is blind to many nonlinear correlations that there may be. Don't trust the above matrices blindly.\n",
    "\n",
    "![Figure from BDN2010](figs/corrcov.png)\n",
    "(figure from C. Delaere slides at the 2010 BND school)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6554c436-6697-4725-bccd-531b38c3104a",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "Before training a first ML-based classifier we need to think about if any preprocessing of the data is required. Many ML algorithms are based on gradient minimization techniques that can fail if the inputs have numbers that widely-vary in magnitude. For example, the $p_T$ of a jet might range from 20 to 2000 GeV, covering several orders of magnitude, and can prevent the convergence of a minimization algorithm. In the case of $p_T$ a typical manual preprocessing could be to use the logarithm as input instead, ie. $\\\\log(p_T/1~\\\\textrm{GeV})$, which in particular moves.\n",
    "\n",
    "In this data set, the features have already been scaled such that their range is around unity. Sometimes this happens naturally, but in this case several variables come directly from particle physics and represent momenta of particles produced in high-energy interaction: when expressed in GeV, these variables will most certainly **not** be in a range close to unity.\n",
    "\n",
    "Common choices to preprocess input features automatically are minmax scaling or normalization.\n",
    "\n",
    "###### Minmax\n",
    "Compress the range linearly:\n",
    "$$X_{scaled} = \\\\frac{X-X_{min}}{X_{max}-X_{min}}$$\n",
    "A drawback is that this results in an artificially smaller variance (the range is compressed linearly), which can deform the effect of outliers.\n",
    "\n",
    "###### Standardization\n",
    "Compress the range and the shape:\n",
    "$$X_{normalized} = \\\\frac{X - \\\\mu}{\\\\sigma}$$\n",
    "where $\\\\mu$ is the mean of the feature values and $\\\\sigma$ is the standard deviation.\\n\",\n",
    "\n",
    "###### Which one?\n",
    "- Typically one would use minmax scaling when your features are remarkably nongaussian and your ML algorithm of choice doesn't require Gaussian inputs. The price is that it affects outliers.\n",
    "- Typically one would use normalization when the features are approximately Gaussian or when your ML algorithm of choice requires Gaussian inputs. However, it also results in numbers close to 1 (minimization algorithms and gradient descend love numbers that are not too large or too small), so it can be used for any algorithm: the good news is that it doesn't affect outliers.\n",
    "\n",
    "You can also apply PCA, as we have discussed in the lectures. The code below imports the most common scalers, for you to play with.\n",
    "\n",
    "For now, let's use the standard scaler for the input features of the dense NN. You are encouraged to try out the others!\n",
    "\n",
    "We will also store the original train and test structures, because for the convolutional network we will preprocess them differently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655bf1cb-b828-4c77-b397-a98a0122c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv = X_train.copy()\n",
    "y_train_conv = y_train.copy()\n",
    "X_test_conv = X_test.copy()\n",
    "y_test_conv = y_test.copy()\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    MaxAbsScaler, # maxAbs\n",
    "    MinMaxScaler, # MinMax\n",
    "    Normalizer, # Normalization (equal integral)\n",
    "    StandardScaler# standard scaling\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Scale the input features and the target variable\n",
    "for column in X_train.columns:\n",
    "    scaler = StandardScaler().fit(X_train.filter([column], axis=1))\n",
    "    X_train[column] = scaler.transform(X_train.filter([column], axis=1))\n",
    "    X_test[column] = scaler.transform(X_test.filter([column], axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fa7702-c11d-4d3e-a8a0-3c090c9e2ef4",
   "metadata": {},
   "source": [
    "You could also use the basic syntax recommended by the documentation, as follows, but then you would be standardizing all the features to exacly the same mean. This may work for some data sets, but for this specific one it does not (it actually significantly worsens the performance---you can try ;) )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee94a2-dc0e-43d5-bd41-7cd57b4d91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler().fit(X_train[X_train.columns])\n",
    "#X_train[X_train.columns] = scaler.transform(X_train[X_train.columns])\n",
    "#X_test[X_test.columns] = scaler.transform(X_test[X_test.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563813ad-37b4-435c-9aa2-42ac9f47375c",
   "metadata": {},
   "source": [
    "## Train a dense neural network\n",
    "\n",
    "\n",
    "For neural networks we will use `pytorch`, a backend designed natively for tensor operations.\n",
    "I prefer it to tensorflow, because it exposes (i.e. you have to call them explicitly in your code) the optimizer steps and the backpropagation steps.\n",
    "\n",
    "You could also use the `tensorflow` backend, either directly or through the `keras` frontend.\n",
    "Saying \"I use keras\" does not tell you which backend is being used. It used to be either `tensorflow` or `theano`. Nowadays `keras` is I think almost embedded inside tensorflow, but it is still good to specify.\n",
    "\n",
    "`torch` handles the data management via the `Dataset` and `DataLoader` classes.\n",
    "Here we don't need any specific `Dataset` class, because we are not doing sophisticated things, but you may need that in the future.\n",
    "\n",
    "The `Dataloader` class takes care of providing quick access to the data by sampling batches that are then fed to the network for (mini)batch gradient descent.\n",
    "                                                                                                                            \n",
    "                                                                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef78064-3c16-4112-8c9e-ec05c2138079",
   "metadata": {},
   "source": [
    "Set a manual seed, for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1d948-1185-41a0-8bd1-013d1910c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9422ec-c810-452b-82f5-edff81dcf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y, device=torch.device(\"cpu\")):\n",
    "        self.X = torch.Tensor(X.values if isinstance(X, pd.core.frame.DataFrame) else X).to(device)\n",
    "        self.y = torch.Tensor(y.values).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        datum = self.X[idx]\n",
    "        \n",
    "        return datum, label\n",
    "\n",
    "batch_size=1024 # Minibatch learning\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "test_dataset = MyDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4b9160-5fe8-4ed9-98ef-dfdce2432046",
   "metadata": {},
   "source": [
    "For educational purposes, let's get access the data loader via its iterator, and sample a single batch by calling `next` on the iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe9146-6213-40c9-a91d-f78341e1e826",
   "metadata": {},
   "source": [
    "Let's build a simple neural network, by inheriting from the `nn.Module` class. **This is very crucial, because that class is the responsible for providing the automatic differentiation infrastructure for tracking parameters and performing backpropagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a1cac-2fe6-4d02-b899-b4ba8b707161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, ninputs, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(ninputs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.linear_relu_stack.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass data through conv1\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1ee743-cc12-4a5e-8e36-65f809b634a6",
   "metadata": {},
   "source": [
    "Let's instantiate the neural network and print some info on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef615813-e4c5-403e-8488-7008cdce36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(X_train.shape[1])\n",
    "\n",
    "print(model) # some basic info\n",
    "\n",
    "print(\"Now let's see some more detailed info by using the torchinfo package\")\n",
    "torchinfo.summary(model, input_size=(batch_size, X_train.shape[1])) # the input size is (batch size, number of features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac26317-34cd-4dc0-870d-7080b4a860cf",
   "metadata": {},
   "source": [
    "Now let's introduce a crucial concept: `torch` lets you manage in which device you want to put your data and models, to optimize access at different stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39cf99c-1c0a-4679-ba59-c7a3b3f9a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "if torch.cuda.is_available() and torch.cuda.device_count()>0:\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "print (\"Available device: \",device)\n",
    "\n",
    "\n",
    "# Get a batch from the dataloader\n",
    "random_batch_X, random_batch_y = next(iter(train_dataloader))\n",
    "\n",
    "print(\"The original dataloader resides in\", random_batch_X.get_device())\n",
    "\n",
    "# Let's reinstantiate the dataset\n",
    "train_dataset = MyDataset(X_train, y_train, device=device)\n",
    "test_dataset = MyDataset(X_test, y_test, device=device)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "random_batch_X, random_batch_y = next(iter(train_dataloader))\n",
    "\n",
    "print(\"The new dataloader puts the batches in in\", random_batch_X.get_device())\n",
    "\n",
    "# Reinstantiate the model, on the chosen device\n",
    "model = NeuralNetwork(X_train.shape[1], device)\n",
    "\n",
    "#check if the NN can be evaluated some data; note: it has not been trained yet\n",
    "print (model(torch.tensor(X_train.values[:10],device=device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe94c7f-186b-47fb-a7e3-65ce99661837",
   "metadata": {},
   "source": [
    "We have learned how load the data into the GPU, how to define and instantiate a model. Now we need to define a training loop.\n",
    "\n",
    "In `keras`, this is wrapped hidden into the `.fit()` method, which I think is bad because it hides the actual procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60e984-c72d-42a3-b04d-73a6b2204af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, scheduler, best_model_path, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    losses=[] # Track the loss function\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    #for batch, (X, y) in enumerate(dataloader):\n",
    "    best_loss = np.inf\n",
    "    for (X,y) in tqdm(dataloader):\n",
    "        # Reset gradients (to avoid their accumulation)\n",
    "        optimizer.zero_grad()\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        #if (all_equal3(pred.detach().numpy())):\n",
    "        #    print(\"All equal!\")\n",
    "        loss = loss_fn(pred.squeeze(dim=1), y)\n",
    "        losses.append(loss.detach().cpu())\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss.detach().cpu()\n",
    "            torch.save(model.state_dict(), best_model_path) # Save the full state of the model, to have access to the training history\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e03ac-147b-4895-85c0-1a77d5cbe2df",
   "metadata": {},
   "source": [
    "Now we need to define the loop that is run on the test dataset.\n",
    "\n",
    "**The test dataset is just used for evaluating the output of the model. No backpropagation is needed, therefore backpropagation must be switched off!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26311c24-455f-41b7-a5b6-0563071dad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    losses=[] # Track the loss function\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        #for X, y in dataloader:\n",
    "        for (X,y) in tqdm(dataloader):\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred.squeeze(dim=1), y).item()\n",
    "            losses.append(loss)\n",
    "            test_loss += loss\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c0895-2ffd-4543-aa29-f40740de3241",
   "metadata": {},
   "source": [
    "We are now read to train this network!\n",
    "At the moment we are trying to do classification. We will set our loss function to be the cross entropy.\n",
    "\n",
    "Torch provides the functionality to use generic functions as loss function. We will show an example one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecfe6e4-082f-4f26-a70b-59d8dea0eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30\n",
    "learningRate = 0.01\n",
    "\n",
    "# The loss defines the metric deciding how good or bad is the prediction of the network\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "# The optimizer decides which path to follow through the gradient of the loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
    "# The scheduler reduces the learning rate for the optimizer in order to for the optimizer to be able to \"enter\" narrow minima\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e19eec4-bf34-440b-ac76-14599477ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses=[]\n",
    "test_losses=[]\n",
    "best_model_path = \"best_dnn_model.h5\"\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss=train_loop(train_dataloader, model, loss_fn, optimizer, scheduler, best_model_path, device)\n",
    "    test_loss=test_loop(test_dataloader, model, loss_fn, device)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    print(\"Avg train loss\", train_loss, \", Avg test loss\", test_loss, \"Current learning rate\", scheduler.get_last_lr())\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c152d78-62b0-43f0-b64d-fcbabd238661",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Average training loss\")\n",
    "plt.plot(test_losses, label=\"Average test loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b53d07-f43d-469a-9b99-c296e12cdc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rocs(scores_labels_names):\n",
    "    plt.figure()\n",
    "    for score, label, name  in scores_labels_names:\n",
    "        fpr, tpr, thresholds = roc_curve(label, score)\n",
    "        plt.plot(\n",
    "            fpr, tpr, \n",
    "            linewidth=2, \n",
    "            label=f\"{name} (AUC = {100.*auc(fpr, tpr): .2f} %)\"\n",
    "        )\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    plt.grid()\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_rocs([\n",
    "    (model(torch.tensor(X_train.to_numpy(),device=model.device)).numpy(force=True), y_train, \"Train\"), \n",
    "    (model(torch.tensor(X_test.to_numpy(),device=model.device)).numpy(force=True), y_test, \"Test\")  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433815d3-bea7-4def-a43c-282a58be0198",
   "metadata": {},
   "source": [
    "#### Explainability\n",
    "\n",
    "A good question to pose yourself is whether the features you have chosen for your data are meaningful variables (i.e. if they are actually relevant to your classifier). Another good question is which features drive the prediction for a given event or set of events.\n",
    "\n",
    "All these questions can be answered by using different concepts:\n",
    "\n",
    "- **Permutation importance**: the decrease in a model score when a single feature value is randomly shuffled (scikit-learn docs) (akin to impacts for profile likelihood fits)\n",
    "Shapley values: based on game theory (see other contribution)\n",
    "Correlation-based: e.g. parallel coordinates in TMVA: look where each variable is mapped\n",
    "to/correlated with\n",
    "\n",
    "- **Perturbational approach**: perturbing the value of a feature and looking at the change of the prediction gives hints on how important the variable is for the method. This is at the basis of LIME (`pip install lime`). You can read more [here](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)\n",
    "\n",
    "- **Game-theoretical approach**: consider the prediction task as a game in game theory, and the features as players who bet via their values. The payout, as difference of prediction with respect to the true value, estimates how much a feature pushes the prediction away from the truth.\n",
    "\n",
    "- **Visual approach**: parallel coordinates, which were implemented in ROOT TMVA, let you handily select a range in the prediction, and have a visual representation of which ranges of each feature is mapped into that region of the prediction.\n",
    "\n",
    "![Parallel coordinates (reference in the figure)](figs/parcoord.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57a6146-4172-4b51-b47f-22eea441c79c",
   "metadata": {},
   "source": [
    "###### Permutation importance\n",
    "\n",
    "The idea is: randomly shuffle one single feature value, then check how much does the prediction change. If the prediction decreases by a lot, then the value of the feature is crucial to the prediction.\n",
    "\n",
    "Note: the importance is always **relative to a specific model**, it has no absolute validity. A feature that is deemed low-importance for a badly designed model may be deemed high-importance for a good model, and vice versa. Permutation importance scores don't \"talk\" across different models.\n",
    "\n",
    "Also, if the model has a performance which is near-chance, then it is not strongly predictive, so the answers one may get from permutation importance scores are not really reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f0f0f-2ab7-44e9-afda-2b539f0215d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "scoring = ['r2', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error']\n",
    "\n",
    "rs = permutation_importance(\n",
    "    model, X_test, y_test, n_repeats=30, random_state=0, scoring=scoring)\n",
    "\n",
    "for metric in rs:\n",
    "    print(f\"{metric}\")\n",
    "    r = rs[metric]\n",
    "    for i in r.importances_mean.argsort()[::-1]:\n",
    "        if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "            print(f\"    {X_train.columns[i]:<8}\" # +1 to skip the label in the naming\n",
    "                  f\"{r.importances_mean[i]:.3f}\"\n",
    "                  f\" +/- {r.importances_std[i]:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab6487c-5b32-4a2a-9985-a1fa9629dbb0",
   "metadata": {},
   "source": [
    "Besides looking at the more important variables, you may also look at the less important, to **prune** them.\n",
    "\n",
    "Pruning consists in dropping the least important variables and retraining your machine learning algorithm.\n",
    "The idea behind it is that the variables dropped don't influence the prediction anyway, and retraining without them should give more or less the same performance but with a simpler model. Why would we do that? Well, for example inference may be time-sensitive, and simpler models are computationally **faster** to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855e7eb6-2b34-4607-9899-8ac8b50ce48a",
   "metadata": {},
   "source": [
    "##### Shapley values\n",
    "(based on [this blog post](https://www.analyticsvidhya.com/blog/2019/11/shapley-value-machine-learning-interpretability-game-theory/))\n",
    "\n",
    "Shapley values are a construct based on game theory.\n",
    "The main idea behind Shapley values is to consider the prediction task for a single event as game played by the feature values of that event. The features collaborate together to play the game by betting. The value of the feature is the amount each feature bets on the prediction task. The **Shapley Value** for each feature is the payout of the game, and consists in the correct weight such that the sum of all Shapley values for the features is the difference between the predictions and the average value of the model. In other words, the Shapley value represents how much each variable pushes the prediction far from the expected value.\n",
    "\n",
    "More concretely, the Shapley value for a feature A is computed as follows:\n",
    "\n",
    "- Get all subsets of features that do not contain A\n",
    "- Compute the effect of adding A to each of these subsets \n",
    "- Aggregate all the contributions (i.e. compute the marginal contribution of the feature over all the subsets)\n",
    "import shap\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(fitted_bdt_grad)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "i = 500\n",
    "shap.force_plot(explainer.expected_value, shap_values[i], features=X_train.iloc[i], feature_names=X_train.columns)\n",
    "In principle we should retrain the model for each of these subsets, but instead we (the `shap` package, actually) will just compute predictions by replacing the value of the feature with its own average value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1957b-c3a2-4198-bb05-40e6b5426810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "i = 500\n",
    "shap.force_plot(explainer.expected_value, shap_values[i], features=X_train.iloc[i], feature_names=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3711593a-5ef3-4fad-a165-d335df118001",
   "metadata": {},
   "source": [
    "Values in blue represent features that push the prediction towards negative values, values in red represent features that push the prediction towards positive values, *for the event number 4776*.\n",
    "\n",
    "We naturally want a summary of Shapley values over all observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14667fc1-2686-42ac-a875-905bc803d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, features=X_train, feature_names=X_train.columns, use_log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3314d-ec3c-48e2-a583-00244d7e95c1",
   "metadata": {},
   "source": [
    "## Train a convolutional neural network\n",
    "\n",
    "We will now build and train a convolutional neural network, which is a special type of neural network that is very well suited to analyze data where features depend on each other depending on a notion of proximity between the features in the data vector ordering.\n",
    "\n",
    "Convolutional neural networks are based on the convolution operation, which provides an input that averages neighbouring features (where neighbour means in terms of the position in the data vector---for an image, closeness of the pixel):\n",
    "\n",
    "\n",
    "$$s(t) = \\int x(a) w(t-a)da$$\n",
    "\n",
    "- When discretized, integral becomes a sum\n",
    "  - $x$ input\n",
    "  - $w$ kernel: specifies how far does the averaging goes\n",
    "  - $s$ feature map\n",
    "\n",
    "Convolutional networks are also based on the concept of `parameter sharing`, that enables invariance by translations (recognize the same pattern in different places of the \"image\"), and of `pooling`, that is averaging classification patterns.\n",
    "\n",
    "To build a convolutional network, we will need to change two main things compared to the dense network:\n",
    "\n",
    "- encode the data in a way that makes them similar to an image\n",
    "- build a network using layers that implement convolution and pooling operations\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c702c5a6-f0f3-476f-b65b-eac00053a757",
   "metadata": {},
   "source": [
    "### Build a 2D \"image\" for the event, based on the $\\eta$ and $\\phi$ coordinates of the leptons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8502df3-14a2-48db-b115-11e7f38e413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digitization courtesy Evan Armstrong König\n",
    "\n",
    "# list all objects that have eta/phi coordinates\n",
    "objects = [\n",
    "    \"Hreco_Lep0\",\n",
    "    \"Hreco_Lep1\",\n",
    "    # \"Hreco_HadTop\",\n",
    "    \"Hreco_All5_Jets\",\n",
    "    # \"Hreco_More5_Jets\",\n",
    "    \"Hreco_Jets_plus_Lep\",\n",
    "    \"Hreco_met\",\n",
    "]\n",
    "\n",
    "def digitize(x, bins):\n",
    "    # digitize x into bins\n",
    "    idx = np.digitize(x, bins) - 1\n",
    "\n",
    "    # clip values outside the bins\n",
    "    idx = np.clip(idx, 0, len(bins)-2)\n",
    "    return idx\n",
    "\n",
    "def build_image(X, Nbins=5, transforms=[]):\n",
    "    \"\"\"\n",
    "    Build a 2d image of energy deposits\n",
    "    \"\"\"\n",
    "\n",
    "    # using the eta and phi coordinates as x and y\n",
    "    for obj in objects:\n",
    "        X[f'{obj}_x'] = X[f'{obj}_eta'] if obj != 'Hreco_met' else 0\n",
    "        X[f'{obj}_y'] = X[f'{obj}_phi']\n",
    "\n",
    "    # apply any transformations to the coordinates\n",
    "    for transform in transforms:\n",
    "        X = transform(X)\n",
    "\n",
    "    index = np.arange(len(X))\n",
    "    eta_edges = np.linspace(-5, 5, Nbins+1)\n",
    "    phi_edges = np.linspace(-3.2, 3.2, Nbins+1)\n",
    "\n",
    "    # create the image with the energy deposits\n",
    "    img = np.zeros((len(X), 1, Nbins, Nbins))\n",
    "    for obj in objects:\n",
    "        et = np.sqrt(X[f\"{obj}_pt\"]**2 + X[f\"{obj}_mass\"]**2) if obj != 'Hreco_met' else X[f\"{obj}\"]\n",
    "        eta_bin = digitize(X[f\"{obj}_x\"], eta_edges)\n",
    "        phi_bin = digitize(X[f\"{obj}_y\"], phi_edges)\n",
    "        img[index, 0, eta_bin, phi_bin] += et\n",
    "\n",
    "    # use the log of the energy instead\n",
    "    img[img > 0] = np.log(img[img > 0])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ed0f6-bb90-435c-bb73-3b90e5f04e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special image feature scaler that ignores the empty pixels in our images\n",
    "class ImageMinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.max = None\n",
    "        self.min = None\n",
    "\n",
    "    def fit(self, img):\n",
    "        self.max = np.array([ F[F != 0].max() for F in img.transpose(1, 0, 2, 3) ])[None, :, None, None]\n",
    "        self.min = np.array([ F[F != 0].min() for F in img.transpose(1, 0, 2, 3) ])[None, :, None, None]\n",
    "\n",
    "    def transform(self, img):\n",
    "        return np.where(img != 0, (img - self.min) / (self.max - self.min), 0)\n",
    "\n",
    "    def fit_transform(self, img):\n",
    "        self.fit(img)\n",
    "        return self.transform(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93421dfe-8c60-48c3-9b68-1858fe351a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ImageMinMaxScaler()\n",
    "\n",
    "Nbins=10\n",
    "img_train = build_image(X_train_conv, Nbins=10)\n",
    "img_test = build_image(X_test_conv, Nbins=10)\n",
    "\n",
    "\n",
    "img_train = scaler.fit_transform(img_train)\n",
    "img_test = scaler.transform(img_test)\n",
    "\n",
    "print (f\"Image format: {img_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c83720-cd00-4eaa-b3a1-605b05f1d1b9",
   "metadata": {},
   "source": [
    "### Display an example image\n",
    "Courtesy Evan Armstrong König\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9995b2d-e4f8-40aa-bc0e-fb4fd55d9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolor\n",
    "\n",
    "norm = mcolor.Normalize(vmin=0, vmax=1)\n",
    "\n",
    "def plot_event_image(ax, img, title):\n",
    "    img = np.where(img != 0, img, np.nan)\n",
    "    c = ax.imshow(img[0], norm=norm)\n",
    "    ax.set_title(title)\n",
    "    return c\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=[12,12])\n",
    "c0 = plot_event_image(axs[0, 0], img_train[0], 'Training Event 0')\n",
    "c1 = plot_event_image(axs[0, 1], img_train[1], 'Training Event 1')\n",
    "c2 = plot_event_image(axs[1, 0], img_train[2], 'Training Event 2')\n",
    "c3 = plot_event_image(axs[1, 1], img_train[3], 'Training Event 3')\n",
    "\n",
    "fig.colorbar(c0, ax=axs)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c538ad-e2a6-44d4-9982-3493de5a7ac6",
   "metadata": {},
   "source": [
    "Now we are ready to build again our dataset and dataloader, in the same way as we did above for the dense NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffafcf61-bbcf-4ff1-9eb0-210d730374bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNNDataset(Dataset):\n",
    "    def __init__(self, X, y, device=torch.device(\"cpu\")):\n",
    "        self.X = torch.Tensor(X.values if isinstance(X, pd.core.frame.DataFrame) else X).to(device)\n",
    "        self.y = torch.Tensor(y.values if isinstance(X, pd.core.frame.DataFrame) else y.to_numpy()).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        datum = self.X[idx]\n",
    "        \n",
    "        return datum, label\n",
    "    \n",
    "train_dataset_conv = MyCNNDataset(img_train, y_train_conv, device=device)\n",
    "test_dataset_conv = MyCNNDataset(img_test, y_test_conv, device=device)\n",
    "\n",
    "batch_size=2048\n",
    "train_dataloader_conv = DataLoader(train_dataset_conv, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader_conv = DataLoader(test_dataset_conv, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a41fd8-418d-42f0-a9fa-6f8006129dc2",
   "metadata": {},
   "source": [
    "We can now build our new convolutional network. The way it typically works is to have a convolutional structure first, to analyze the image and extract its relevant features, and then a small linear (dense) layer or set of layers to perform the final classification task.\n",
    "\n",
    "Relevant parameters for a convolutional layer are the number of input and of output channels. Channels are the representations of the same image area in different ways: for instance, a black-and-white image has $n\\times m$ pixels and one channel (the grey scale); an RGB image has three channels: one $n\\times m$ array per each of the three primary colours. This can be generalized to any \"pseudo-image\" you may be trying to use. The output channels refer to the amount of simultaneous representations of the image (each one through one different convolutional kernel) should be produced by the convolutional layer. It is advantageous to set a non-1 value for the number of output channels of a convolutional layer, because (by requiring one kernel per each of the output channels) it results in learnable parameters that can focus on different aspects of the \"image\".\n",
    "\n",
    "For our application, the number of channels will be determined by the procedure we used to digitize the input data into \"images\", therefore we will take if from the batch characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28cf76c-a16d-406c-ad19-bf819f828e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_x, batch_y = next(iter(train_dataloader_conv))\n",
    "_, n_channels, img_height, img_width = batch_x.shape\n",
    "print(batch_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf91f8-fb2f-4280-85e1-282e1ead3264",
   "metadata": {},
   "source": [
    "We are now ready to build the model, which will be made out of two part:\n",
    "- a convolutional part, tasked with image processing\n",
    "- a dense part, tasked with the final classification.\n",
    "\n",
    "We will select a kernel size of $(2,2)$, indicating that we want to average only the pixels in the immediate vicinities. You can play with this parameter.\n",
    "\n",
    "In the structure below, the first `Conv2d` layer has $32$ output channels and therefore it has $32$ kernels (each of the specified size $2x2$), i.e. splits the image in thirty-two separate channels each with its own convolution operation. Padding ensures the size of the image remains the same. The second Conv2d layer has $16$ filters, also with a $3x3$ kernel.\n",
    "\n",
    "The MaxPool2d layer has a 2x2 kernel and a stride of 2. This does averaging and dimensional reduction, downsampling the image by a factor 2 in each dimension (from 28x28 to 14x14 the first time we apply it, and from 14x14 to 7x7 the second time).\n",
    "\n",
    "The output of the second Conv2d layer will therefore a 16-channel image where each channel is 7x7. We flatten it to a one-dimensional vector per image to feed it to a dense layer that does classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5e821-4e48-4254-b396-f2e7719a1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork(nn.Module):\n",
    "    def __init__(self, in_channels, height, width, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(), \n",
    "            # For MaxPool2d, dim_out = (dim_in + 2*padding - dilation *(kernelsize-1) -1)/stride -1 , default dilation is 1, default padding 0\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 1)), \n",
    "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            # We won't put another pooling layer, because the \"image\" is already rather small            \n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.conv.to(self.device)\n",
    "        # acquire the output shape of the convolutional layer\n",
    "        _, F = self.conv(torch.zeros(1, in_channels, height, width, device=self.device)).shape\n",
    "        self.dense = nn.Sequential(\n",
    "            # acquire the output shape of the convolutional layer\n",
    "            nn.Linear(F, int(F/2)),\n",
    "            nn.Linear(int(F/2), 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.dense.to(self.device)\n",
    "            # Another activation function here? Or not?\n",
    "    def set_device(self, device):\n",
    "        # Needed to fix the issue with conv2d channels in pytorch under MPS devices (fixed in torch 2.7.0.dev20250105 and above)\n",
    "        self.device=device\n",
    "        self.conv.to(device)\n",
    "        self.dense.to(device)\n",
    "    def forward(self, x):\n",
    "        x.to(self.device)\n",
    "        x = self.conv(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2290733-5c21-4c68-8b27-32b049231c06",
   "metadata": {},
   "source": [
    "Let's instantiate the model and print some info on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb4757-c862-4c5c-b53e-e7712f9d457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = ConvNetwork(n_channels, img_height, img_width, device=device)\n",
    "print(conv_model) # some basic info\n",
    "conv_model(batch_x)\n",
    "print(\"Now let's see some more detailed info by using the torchinfo package\")\n",
    "torchinfo.summary(conv_model, input_size=batch_x.shape, device=device) # the input size is (batch size, number of features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492482a6-1052-425a-bfaa-6a45bbef24d2",
   "metadata": {},
   "source": [
    "### Number of parameters\n",
    "\n",
    "The convolutional network we are using has about 3k parameters, whereas the dense networks has about 90k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e55b11-e9bc-49b7-be30-afc1d343345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainable_parameters(mod):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, mod.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n",
    "print(f\"The dense network has: {get_trainable_parameters(model)} trainable parameters\")\n",
    "print(f\"The convolutional network has {get_trainable_parameters(conv_model)} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe7516-19d7-4706-82ce-38af925c2f13",
   "metadata": {},
   "source": [
    "### Train the convolutional network\n",
    "\n",
    "We can now train the convolutional neural network. Since the target is the same (classification), we can use exactly the same settings and training/test loops:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989bbc1a-b256-4884-8655-9efc71e19171",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=30\n",
    "learningRate = 0.1\n",
    "\n",
    "# The loss defines the metric deciding how good or bad is the prediction of the network\n",
    "conv_loss_fn = torch.nn.BCELoss()\n",
    "# The optimizer decides which path to follow through the gradient of the loss function\n",
    "conv_optimizer = torch.optim.SGD(conv_model.parameters(), lr=learningRate)\n",
    "# The scheduler reduces the learning rate for the optimizer in order to for the optimizer to be able to \"enter\" narrow minima\n",
    "conv_scheduler = torch.optim.lr_scheduler.ExponentialLR(conv_optimizer, gamma=0.9)\n",
    "\n",
    "conv_train_losses=[]\n",
    "conv_test_losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25668e1a-79a6-42df-a081-0359f62d8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_conv_model_path = './best_cnn_model.h5'\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss=train_loop(train_dataloader_conv, conv_model, conv_loss_fn, conv_optimizer, conv_scheduler, best_conv_model_path, device)\n",
    "    test_loss=test_loop(test_dataloader_conv, conv_model, conv_loss_fn, device)\n",
    "    conv_train_losses.append(train_loss)\n",
    "    conv_test_losses.append(test_loss)\n",
    "    print(\"Avg train loss\", train_loss, \", Avg test loss\", test_loss, \"Current learning rate\", conv_scheduler.get_last_lr())\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2483bf8a-3c79-4f69-a579-d5dcff97066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Average training loss\")\n",
    "plt.plot(test_losses, label=\"Average test loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d6615c-d6de-4b2d-b650-61e8ba80a663",
   "metadata": {},
   "source": [
    "We can now compare the ROC curves obtained for the convolutional network with those obtained for the dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec196a-fa73-4add-9a9d-a5be6fe3305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rocs(scores_labels_names):\n",
    "    plt.figure()\n",
    "    for score, label, name  in scores_labels_names:\n",
    "        fpr, tpr, thresholds = roc_curve(label, score)\n",
    "        plt.plot(\n",
    "            fpr, tpr, \n",
    "            linewidth=2, \n",
    "            label=f\"{name} (AUC = {100.*auc(fpr, tpr): .2f} %)\"\n",
    "        )\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    plt.grid()\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "conv_model.set_device(torch.device(\"cpu\"))\n",
    "conv_model.to(torch.device(\"cpu\"))\n",
    "\n",
    "plot_rocs([\n",
    "    (model(torch.tensor(X_train.to_numpy(),device=model.device)).numpy(force=True), y_train, \"DNN, train\"), \n",
    "    (model(torch.tensor(X_test.to_numpy(),device=model.device)).numpy(force=True), y_test, \"DNN, test\"),\n",
    "    (conv_model(torch.tensor(img_train, device=conv_model.device, dtype=torch.float32)).detach().numpy(), y_train_conv, \"CNN, train\"), \n",
    "    (conv_model(torch.tensor(img_test, device=conv_model.device, dtype=torch.float32)).detach().numpy(), y_test_conv, \"CNN, test\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d4d19-62ca-4f05-8871-06ff3f10d699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
